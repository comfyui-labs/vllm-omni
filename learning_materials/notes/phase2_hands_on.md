# 阶段二：快速上手（1 周）

目标：跑通最小可用示例，理解调用链与输入/输出结构。

## 建议步骤

1. 跟随 vLLM-Omni 文档完成最小示例
   - https://vllm-omni.readthedocs.io/
2. 运行 `examples/offline_inference` 下的最小示例
   - 文生图 / 文生音频 / 多模态对话

## 关键观察点

- `Omni` 入口如何加载模型与 stage configs
- `Omni.generate()` 的请求/输出结构
- Diffusion 与 AR 的采样参数差异

## 输出记录模板

- 模型名称：
- 任务类型：
- 运行参数：
- 结果产物：
- 运行时间与显存占用：
